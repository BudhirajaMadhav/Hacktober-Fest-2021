{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62f7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5b51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "#nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0289f",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680e4f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./labeledTrainData.tsv/labeledTrainData.tsv', delimiter='\\t', header=0, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3750cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./testData.tsv/testData.tsv', delimiter='\\t', header=0, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a446751",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_train = pd.read_csv('./unlabeledTrainData.tsv/unlabeledTrainData.tsv', delimiter='\\t', header=0, quoting=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f8ccb",
   "metadata": {},
   "source": [
    "# Reviewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5041a5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000 50000\n"
     ]
    }
   ],
   "source": [
    "print(train['review'].size, test['review'].size, unlabeled_train['review'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e064767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff3d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist( review, remove_stopwords = False):\n",
    "    \n",
    "    #removing html\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    #lowering words\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    #removing stopwords ( False by default )\n",
    "    if remove_stopwords:\n",
    "        \n",
    "        stop = set(stopwords.words('english'))\n",
    "        words = [w for w in words if w not in stop]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a6da85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.data\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81600004",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53dc30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_sentences( review, tokenizer, remove_stopwords = False):\n",
    "    \n",
    "    # Splitting paragraphs into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    #Filtering sentences\n",
    "    for raw_sentence in raw_sentences:\n",
    "        \n",
    "        if len(raw_sentence) > 0:\n",
    "            \n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d7feac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.happierabroad.com\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from unlabeled set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.archive.org/details/LovefromaStranger\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.loosechangeguide.com/LooseChangeGuide.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \"... ...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \"....\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.msnbc.msn.com/id/4972055/site/newsweek/\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \"..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.youtube.com/watch?v=a0KSqelmgN8\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \".. .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ishant\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:417: MarkupResemblesLocatorWarning: \"http://jake-weird.blogspot.com/2007/08/beneath.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "print (\"Parsing sentences from training set\")\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "print (\"Parsing sentences from unlabeled set\")\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "    \n",
    "#might get warning due to urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b10fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795538\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd601a",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1fe2467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:50:30,617 : INFO : collecting all words and their counts\n",
      "2021-10-05 12:50:30,617 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-10-05 12:50:30,659 : INFO : PROGRESS: at sentence #10000, processed 219242 words, keeping 32665 word types\n",
      "2021-10-05 12:50:30,716 : INFO : PROGRESS: at sentence #20000, processed 438623 words, keeping 51663 word types\n",
      "2021-10-05 12:50:30,765 : INFO : PROGRESS: at sentence #30000, processed 651476 words, keeping 66881 word types\n",
      "2021-10-05 12:50:30,813 : INFO : PROGRESS: at sentence #40000, processed 871114 words, keeping 80990 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:50:30,863 : INFO : PROGRESS: at sentence #50000, processed 1083691 words, keeping 93535 word types\n",
      "2021-10-05 12:50:30,924 : INFO : PROGRESS: at sentence #60000, processed 1298869 words, keeping 104807 word types\n",
      "2021-10-05 12:50:30,980 : INFO : PROGRESS: at sentence #70000, processed 1515513 words, keeping 115640 word types\n",
      "2021-10-05 12:50:31,034 : INFO : PROGRESS: at sentence #80000, processed 1728384 words, keeping 125785 word types\n",
      "2021-10-05 12:50:31,078 : INFO : PROGRESS: at sentence #90000, processed 1945448 words, keeping 136196 word types\n",
      "2021-10-05 12:50:31,135 : INFO : PROGRESS: at sentence #100000, processed 2160633 words, keeping 145760 word types\n",
      "2021-10-05 12:50:31,182 : INFO : PROGRESS: at sentence #110000, processed 2373736 words, keeping 154951 word types\n",
      "2021-10-05 12:50:31,235 : INFO : PROGRESS: at sentence #120000, processed 2589502 words, keeping 164045 word types\n",
      "2021-10-05 12:50:31,295 : INFO : PROGRESS: at sentence #130000, processed 2808001 words, keeping 173092 word types\n",
      "2021-10-05 12:50:31,351 : INFO : PROGRESS: at sentence #140000, processed 3014647 words, keeping 180730 word types\n",
      "2021-10-05 12:50:31,411 : INFO : PROGRESS: at sentence #150000, processed 3233786 words, keeping 189190 word types\n",
      "2021-10-05 12:50:31,467 : INFO : PROGRESS: at sentence #160000, processed 3449518 words, keeping 197400 word types\n",
      "2021-10-05 12:50:31,542 : INFO : PROGRESS: at sentence #170000, processed 3666036 words, keeping 205202 word types\n",
      "2021-10-05 12:50:31,622 : INFO : PROGRESS: at sentence #180000, processed 3880006 words, keeping 212718 word types\n",
      "2021-10-05 12:50:31,689 : INFO : PROGRESS: at sentence #190000, processed 4098458 words, keeping 220316 word types\n",
      "2021-10-05 12:50:31,765 : INFO : PROGRESS: at sentence #200000, processed 4315770 words, keeping 227814 word types\n",
      "2021-10-05 12:50:31,849 : INFO : PROGRESS: at sentence #210000, processed 4530864 words, keeping 235183 word types\n",
      "2021-10-05 12:50:31,920 : INFO : PROGRESS: at sentence #220000, processed 4749178 words, keeping 242719 word types\n",
      "2021-10-05 12:50:31,973 : INFO : PROGRESS: at sentence #230000, processed 4965224 words, keeping 249871 word types\n",
      "2021-10-05 12:50:32,036 : INFO : PROGRESS: at sentence #240000, processed 5186072 words, keeping 256947 word types\n",
      "2021-10-05 12:50:32,083 : INFO : PROGRESS: at sentence #250000, processed 5393721 words, keeping 263710 word types\n",
      "2021-10-05 12:50:32,157 : INFO : PROGRESS: at sentence #260000, processed 5606855 words, keeping 270573 word types\n",
      "2021-10-05 12:50:32,233 : INFO : PROGRESS: at sentence #270000, processed 5821731 words, keeping 277451 word types\n",
      "2021-10-05 12:50:32,323 : INFO : PROGRESS: at sentence #280000, processed 6040767 words, keeping 284594 word types\n",
      "2021-10-05 12:50:32,411 : INFO : PROGRESS: at sentence #290000, processed 6257421 words, keeping 291795 word types\n",
      "2021-10-05 12:50:32,497 : INFO : PROGRESS: at sentence #300000, processed 6475443 words, keeping 298856 word types\n",
      "2021-10-05 12:50:32,569 : INFO : PROGRESS: at sentence #310000, processed 6693957 words, keeping 305881 word types\n",
      "2021-10-05 12:50:32,632 : INFO : PROGRESS: at sentence #320000, processed 6912070 words, keeping 312702 word types\n",
      "2021-10-05 12:50:32,695 : INFO : PROGRESS: at sentence #330000, processed 7127006 words, keeping 319343 word types\n",
      "2021-10-05 12:50:32,754 : INFO : PROGRESS: at sentence #340000, processed 7349526 words, keeping 326367 word types\n",
      "2021-10-05 12:50:32,815 : INFO : PROGRESS: at sentence #350000, processed 7566089 words, keeping 332785 word types\n",
      "2021-10-05 12:50:32,868 : INFO : PROGRESS: at sentence #360000, processed 7780210 words, keeping 339214 word types\n",
      "2021-10-05 12:50:32,947 : INFO : PROGRESS: at sentence #370000, processed 8000734 words, keeping 345893 word types\n",
      "2021-10-05 12:50:33,058 : INFO : PROGRESS: at sentence #380000, processed 8218802 words, keeping 352385 word types\n",
      "2021-10-05 12:50:33,150 : INFO : PROGRESS: at sentence #390000, processed 8441561 words, keeping 358863 word types\n",
      "2021-10-05 12:50:33,237 : INFO : PROGRESS: at sentence #400000, processed 8657763 words, keeping 364962 word types\n",
      "2021-10-05 12:50:33,304 : INFO : PROGRESS: at sentence #410000, processed 8872437 words, keeping 370920 word types\n",
      "2021-10-05 12:50:33,369 : INFO : PROGRESS: at sentence #420000, processed 9086761 words, keeping 377047 word types\n",
      "2021-10-05 12:50:33,433 : INFO : PROGRESS: at sentence #430000, processed 9307298 words, keeping 383392 word types\n",
      "2021-10-05 12:50:33,491 : INFO : PROGRESS: at sentence #440000, processed 9527258 words, keeping 389543 word types\n",
      "2021-10-05 12:50:33,549 : INFO : PROGRESS: at sentence #450000, processed 9744341 words, keeping 395673 word types\n",
      "2021-10-05 12:50:33,606 : INFO : PROGRESS: at sentence #460000, processed 9970201 words, keeping 402122 word types\n",
      "2021-10-05 12:50:33,686 : INFO : PROGRESS: at sentence #470000, processed 10191309 words, keeping 408031 word types\n",
      "2021-10-05 12:50:33,772 : INFO : PROGRESS: at sentence #480000, processed 10405372 words, keeping 413650 word types\n",
      "2021-10-05 12:50:33,855 : INFO : PROGRESS: at sentence #490000, processed 10625269 words, keeping 419851 word types\n",
      "2021-10-05 12:50:33,908 : INFO : PROGRESS: at sentence #500000, processed 10840268 words, keeping 425623 word types\n",
      "2021-10-05 12:50:33,991 : INFO : PROGRESS: at sentence #510000, processed 11058615 words, keeping 431582 word types\n",
      "2021-10-05 12:50:34,090 : INFO : PROGRESS: at sentence #520000, processed 11275224 words, keeping 437401 word types\n",
      "2021-10-05 12:50:34,175 : INFO : PROGRESS: at sentence #530000, processed 11492901 words, keeping 443014 word types\n",
      "2021-10-05 12:50:34,249 : INFO : PROGRESS: at sentence #540000, processed 11710358 words, keeping 449016 word types\n",
      "2021-10-05 12:50:34,313 : INFO : PROGRESS: at sentence #550000, processed 11929146 words, keeping 454633 word types\n",
      "2021-10-05 12:50:34,379 : INFO : PROGRESS: at sentence #560000, processed 12143523 words, keeping 460126 word types\n",
      "2021-10-05 12:50:34,446 : INFO : PROGRESS: at sentence #570000, processed 12365281 words, keeping 465767 word types\n",
      "2021-10-05 12:50:34,505 : INFO : PROGRESS: at sentence #580000, processed 12580155 words, keeping 471302 word types\n",
      "2021-10-05 12:50:34,566 : INFO : PROGRESS: at sentence #590000, processed 12799201 words, keeping 476784 word types\n",
      "2021-10-05 12:50:34,628 : INFO : PROGRESS: at sentence #600000, processed 13014825 words, keeping 481902 word types\n",
      "2021-10-05 12:50:34,685 : INFO : PROGRESS: at sentence #610000, processed 13229257 words, keeping 487440 word types\n",
      "2021-10-05 12:50:34,761 : INFO : PROGRESS: at sentence #620000, processed 13448553 words, keeping 492684 word types\n",
      "2021-10-05 12:50:34,823 : INFO : PROGRESS: at sentence #630000, processed 13666159 words, keeping 497936 word types\n",
      "2021-10-05 12:50:34,884 : INFO : PROGRESS: at sentence #640000, processed 13880391 words, keeping 503161 word types\n",
      "2021-10-05 12:50:34,962 : INFO : PROGRESS: at sentence #650000, processed 14099443 words, keeping 508415 word types\n",
      "2021-10-05 12:50:35,051 : INFO : PROGRESS: at sentence #660000, processed 14315314 words, keeping 513726 word types\n",
      "2021-10-05 12:50:35,139 : INFO : PROGRESS: at sentence #670000, processed 14531988 words, keeping 518638 word types\n",
      "2021-10-05 12:50:35,230 : INFO : PROGRESS: at sentence #680000, processed 14750043 words, keeping 523938 word types\n",
      "2021-10-05 12:50:35,317 : INFO : PROGRESS: at sentence #690000, processed 14965705 words, keeping 528846 word types\n",
      "2021-10-05 12:50:35,386 : INFO : PROGRESS: at sentence #700000, processed 15187631 words, keeping 534264 word types\n",
      "2021-10-05 12:50:35,455 : INFO : PROGRESS: at sentence #710000, processed 15403936 words, keeping 539204 word types\n",
      "2021-10-05 12:50:35,511 : INFO : PROGRESS: at sentence #720000, processed 15622458 words, keeping 544103 word types\n",
      "2021-10-05 12:50:35,595 : INFO : PROGRESS: at sentence #730000, processed 15842196 words, keeping 549093 word types\n",
      "2021-10-05 12:50:35,661 : INFO : PROGRESS: at sentence #740000, processed 16056639 words, keeping 553964 word types\n",
      "2021-10-05 12:50:35,736 : INFO : PROGRESS: at sentence #750000, processed 16268597 words, keeping 558719 word types\n",
      "2021-10-05 12:50:35,811 : INFO : PROGRESS: at sentence #760000, processed 16481533 words, keeping 563563 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:50:35,889 : INFO : PROGRESS: at sentence #770000, processed 16701810 words, keeping 568626 word types\n",
      "2021-10-05 12:50:35,962 : INFO : PROGRESS: at sentence #780000, processed 16924889 words, keeping 573568 word types\n",
      "2021-10-05 12:50:36,027 : INFO : PROGRESS: at sentence #790000, processed 17144985 words, keeping 578535 word types\n",
      "2021-10-05 12:50:36,064 : INFO : collected 581308 word types from a corpus of 17264346 raw words and 795538 sentences\n",
      "2021-10-05 12:50:36,065 : INFO : Creating a fresh vocabulary\n",
      "2021-10-05 12:50:36,355 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=40 retains 20587 unique words (3.5414960743702135%% of original 581308, drops 560721)', 'datetime': '2021-10-05T12:50:36.355187', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-10-05 12:50:36,355 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=40 leaves 15706923 word corpus (90.97896323440227%% of original 17264346, drops 1557423)', 'datetime': '2021-10-05T12:50:36.355187', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-10-05 12:50:36,486 : INFO : deleting the raw counts dictionary of 581308 items\n",
      "2021-10-05 12:50:36,502 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2021-10-05 12:50:36,517 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 11694391.261833705 word corpus (74.5%% of prior 15706923)', 'datetime': '2021-10-05T12:50:36.517783', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-10-05 12:50:36,694 : INFO : estimated required memory for 20587 words and 100 dimensions: 26763100 bytes\n",
      "2021-10-05 12:50:36,695 : INFO : resetting layer weights\n",
      "2021-10-05 12:50:36,710 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-10-05T12:50:36.709097', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-10-05 12:50:36,711 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 20587 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2021-10-05T12:50:36.711096', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-10-05 12:50:37,728 : INFO : EPOCH 1 - PROGRESS: at 13.60% examples, 1566583 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:38,729 : INFO : EPOCH 1 - PROGRESS: at 23.39% examples, 1351350 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:39,732 : INFO : EPOCH 1 - PROGRESS: at 33.59% examples, 1293959 words/s, in_qsize 6, out_qsize 1\n",
      "2021-10-05 12:50:40,735 : INFO : EPOCH 1 - PROGRESS: at 47.33% examples, 1373530 words/s, in_qsize 8, out_qsize 0\n",
      "2021-10-05 12:50:41,738 : INFO : EPOCH 1 - PROGRESS: at 60.86% examples, 1416882 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:42,744 : INFO : EPOCH 1 - PROGRESS: at 74.55% examples, 1445856 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:43,745 : INFO : EPOCH 1 - PROGRESS: at 88.02% examples, 1464159 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:44,616 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-05 12:50:44,620 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-05 12:50:44,622 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-05 12:50:44,625 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-05 12:50:44,625 : INFO : EPOCH - 1 : training on 17264346 raw words (11692813 effective words) took 7.9s, 1478670 effective words/s\n",
      "2021-10-05 12:50:45,632 : INFO : EPOCH 2 - PROGRESS: at 13.37% examples, 1554332 words/s, in_qsize 8, out_qsize 0\n",
      "2021-10-05 12:50:46,635 : INFO : EPOCH 2 - PROGRESS: at 27.27% examples, 1581664 words/s, in_qsize 6, out_qsize 1\n",
      "2021-10-05 12:50:47,637 : INFO : EPOCH 2 - PROGRESS: at 40.95% examples, 1585957 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:48,639 : INFO : EPOCH 2 - PROGRESS: at 54.76% examples, 1594314 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:49,642 : INFO : EPOCH 2 - PROGRESS: at 68.46% examples, 1596066 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:50,646 : INFO : EPOCH 2 - PROGRESS: at 82.08% examples, 1594845 words/s, in_qsize 8, out_qsize 0\n",
      "2021-10-05 12:50:51,647 : INFO : EPOCH 2 - PROGRESS: at 95.71% examples, 1594002 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:51,956 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-05 12:50:51,960 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-05 12:50:51,962 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-05 12:50:51,965 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-05 12:50:51,966 : INFO : EPOCH - 2 : training on 17264346 raw words (11693533 effective words) took 7.3s, 1594349 effective words/s\n",
      "2021-10-05 12:50:52,978 : INFO : EPOCH 3 - PROGRESS: at 13.37% examples, 1544130 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:53,979 : INFO : EPOCH 3 - PROGRESS: at 27.16% examples, 1571972 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:54,980 : INFO : EPOCH 3 - PROGRESS: at 40.95% examples, 1584239 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:55,982 : INFO : EPOCH 3 - PROGRESS: at 54.42% examples, 1582924 words/s, in_qsize 8, out_qsize 0\n",
      "2021-10-05 12:50:56,985 : INFO : EPOCH 3 - PROGRESS: at 67.99% examples, 1584266 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:57,981 : INFO : EPOCH 3 - PROGRESS: at 79.18% examples, 1538038 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:58,982 : INFO : EPOCH 3 - PROGRESS: at 92.82% examples, 1546224 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:50:59,491 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-05 12:50:59,504 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-05 12:50:59,508 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-05 12:50:59,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-05 12:50:59,511 : INFO : EPOCH - 3 : training on 17264346 raw words (11692845 effective words) took 7.5s, 1550718 effective words/s\n",
      "2021-10-05 12:51:00,509 : INFO : EPOCH 4 - PROGRESS: at 12.32% examples, 1431136 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:51:01,511 : INFO : EPOCH 4 - PROGRESS: at 25.35% examples, 1471751 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:51:02,514 : INFO : EPOCH 4 - PROGRESS: at 38.99% examples, 1510755 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:51:03,517 : INFO : EPOCH 4 - PROGRESS: at 52.66% examples, 1533892 words/s, in_qsize 8, out_qsize 0\n",
      "2021-10-05 12:51:04,528 : INFO : EPOCH 4 - PROGRESS: at 66.07% examples, 1541033 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:51:05,529 : INFO : EPOCH 4 - PROGRESS: at 79.54% examples, 1546345 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:51:06,519 : INFO : EPOCH 4 - PROGRESS: at 93.15% examples, 1553271 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:51:07,016 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-05 12:51:07,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-05 12:51:07,027 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-05 12:51:07,032 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-05 12:51:07,034 : INFO : EPOCH - 4 : training on 17264346 raw words (11693912 effective words) took 7.5s, 1555913 effective words/s\n",
      "2021-10-05 12:51:08,032 : INFO : EPOCH 5 - PROGRESS: at 13.84% examples, 1601856 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:51:09,035 : INFO : EPOCH 5 - PROGRESS: at 27.72% examples, 1605588 words/s, in_qsize 8, out_qsize 0\n",
      "2021-10-05 12:51:10,038 : INFO : EPOCH 5 - PROGRESS: at 41.64% examples, 1610050 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:51:11,040 : INFO : EPOCH 5 - PROGRESS: at 55.00% examples, 1599526 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:51:12,043 : INFO : EPOCH 5 - PROGRESS: at 68.64% examples, 1599519 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-05 12:51:13,045 : INFO : EPOCH 5 - PROGRESS: at 82.26% examples, 1598391 words/s, in_qsize 8, out_qsize 0\n",
      "2021-10-05 12:51:14,056 : INFO : EPOCH 5 - PROGRESS: at 95.81% examples, 1595544 words/s, in_qsize 8, out_qsize 0\n",
      "2021-10-05 12:51:14,347 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-05 12:51:14,362 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-05 12:51:14,366 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-05 12:51:14,369 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-05 12:51:14,369 : INFO : EPOCH - 5 : training on 17264346 raw words (11694439 effective words) took 7.3s, 1595809 effective words/s\n",
      "2021-10-05 12:51:14,370 : INFO : Word2Vec lifecycle event {'msg': 'training on 86321730 raw words (58467542 effective words) took 37.7s, 1552565 effective words/s', 'datetime': '2021-10-05T12:51:14.370460', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-10-05 12:51:14,371 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20587, vector_size=100, alpha=0.025)', 'datetime': '2021-10-05T12:51:14.370460', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "<ipython-input-20-8843e332a9d5>:19: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n",
      "2021-10-05 12:51:14,401 : WARNING : destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    }
   ],
   "source": [
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters                     \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59d0b4",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3979c625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"france england germany berlin\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "725ef6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man,', 0.8674203157424927),\n",
       " ('man.', 0.7748789191246033),\n",
       " ('woman', 0.7342656850814819),\n",
       " ('lad', 0.7275235056877136),\n",
       " ('soldier', 0.7173106670379639),\n",
       " ('boy', 0.7072140574455261),\n",
       " ('doctor', 0.6941220760345459),\n",
       " ('guy', 0.6815625429153442),\n",
       " ('person', 0.6745182275772095),\n",
       " (\"man's\", 0.6629161238670349)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2fc0100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('atrocious', 0.8013814091682434),\n",
       " ('horrible', 0.7545210123062134),\n",
       " ('terrible', 0.7498117089271545),\n",
       " ('dreadful', 0.737442135810852),\n",
       " ('horrendous', 0.7007668018341064),\n",
       " ('awful,', 0.6943765878677368),\n",
       " ('horrid', 0.6922485828399658),\n",
       " ('appalling', 0.6758695840835571),\n",
       " ('amateurish', 0.6719341278076172),\n",
       " ('abysmal', 0.6670199036598206)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"awful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8469802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
